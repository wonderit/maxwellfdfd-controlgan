{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## MaxwellFDFD Data download\n",
    "1. download data from link\n",
    "2. make directory\n",
    "3. unzip dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:03 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:04 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:05 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:06 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:07 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:08 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:09 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:10 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:11 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:12 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:13 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:14 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:15 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:16 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:17 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:18 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:19 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:20 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:21 --:--:--     0\n",
      "100   377    0   377    0     0     17      0 --:--:--  0:00:21 --:--:--    87\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:22 --:--:--     0\n",
      "100 8143k    0 8143k    0     0   354k      0 --:--:--  0:00:23 --:--:-- 8404k\n",
      "100 17.8M    0 17.8M    0     0   760k      0 --:--:--  0:00:24 --:--:-- 9271k\n",
      "100 20.6M    0 20.6M    0     0   882k      0 --:--:--  0:00:24 --:--:-- 9483k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o maxwellfdfd.zip https://drive.google.com/uc?id=14-Bl89OzRtLM1MCW2H81Xvivq8EvTrmB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#!mkdir maxwellfdfd\n",
    "#!unzip maxwellfdfd.zip -d ./maxwellfdfd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML(Random Forest regressor):\n",
    "1. create model for Multi-output Random Forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\2.CEM\\\\maxwellfdfd-controlgan\\\\maxwellfdfd'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "data_dir = os.path.join(os.getcwd(), 'maxwellfdfd')\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compress_image(prev_image, n):\n",
    "    if n < 2:\n",
    "        return prev_image\n",
    "\n",
    "    height = prev_image.shape[0] // n\n",
    "    width = prev_image.shape[1] // n\n",
    "    new_image = np.zeros((height, width), dtype=int)\n",
    "    for i in range(0, height):\n",
    "        for j in range(0, width):\n",
    "            new_image[i, j] = prev_image[n * i, n * j]\n",
    "\n",
    "    return new_image\n",
    "\n",
    "DATASETS_TRAIN = [\n",
    "    'binary_501',\n",
    "    'binary_502',\n",
    "    'binary_503',\n",
    "    'binary_504',\n",
    "    'binary_505',\n",
    "    'binary_506',\n",
    "    'binary_507',\n",
    "    'binary_508',\n",
    "    'binary_509',\n",
    "    'binary_510',\n",
    "    'binary_511',\n",
    "    'binary_512',\n",
    "    'binary_1001',\n",
    "    'binary_1002',\n",
    "    'binary_1003',\n",
    "    'binary_rl_fix_501',\n",
    "    'binary_rl_fix_502',\n",
    "    'binary_rl_fix_503',\n",
    "    'binary_rl_fix_504',\n",
    "    'binary_rl_fix_505',\n",
    "    'binary_rl_fix_506',\n",
    "    'binary_rl_fix_507',\n",
    "    'binary_rl_fix_508',\n",
    "    'binary_rl_fix_509',\n",
    "    'binary_rl_fix_510',\n",
    "    'binary_rl_fix_511',\n",
    "    'binary_rl_fix_512',\n",
    "    'binary_rl_fix_513',\n",
    "    'binary_rl_fix_514',\n",
    "    'binary_rl_fix_515',\n",
    "    'binary_rl_fix_516',\n",
    "    'binary_rl_fix_517',\n",
    "    'binary_rl_fix_518',\n",
    "    'binary_rl_fix_519',\n",
    "    'binary_rl_fix_520',\n",
    "    'binary_rl_fix_1001',\n",
    "    'binary_rl_fix_1002',\n",
    "    'binary_rl_fix_1003',\n",
    "    'binary_rl_fix_1004',\n",
    "    'binary_rl_fix_1005',\n",
    "    'binary_rl_fix_1006',\n",
    "    'binary_rl_fix_1007',\n",
    "    'binary_rl_fix_1008',\n",
    "]\n",
    "\n",
    "DATASETS_TEST = [\n",
    "    'binary_new_test_501',\n",
    "    'binary_new_test_1501',\n",
    "    'binary_test_1101',\n",
    "]\n",
    "\n",
    "def cem_dataset(train=True):\n",
    "    if train:\n",
    "        DATAPATH = os.path.join(data_dir, 'train')\n",
    "        DATASETS = DATASETS_TRAIN\n",
    "    else:\n",
    "        DATAPATH = os.path.join(data_dir, 'test')\n",
    "        DATASETS = DATASETS_TEST\n",
    "    width = 40\n",
    "    height = 20\n",
    "    input_data = []\n",
    "    targets = []\n",
    "    # load Train dataset\n",
    "    for data in DATASETS:\n",
    "        dataframe = pd.read_csv(os.path.join(DATAPATH, '{}.csv'.format(data)), delim_whitespace=False, header=None)\n",
    "        dataset = dataframe.values\n",
    "\n",
    "        # split into input (X) and output (Y) variables\n",
    "        fileNames = dataset[:, 0]\n",
    "\n",
    "        # 1. first try max\n",
    "        dataset[:, 1:25] /= 2767.1\n",
    "\n",
    "        # 2. Classification or Regression,\n",
    "        labels = dataset[:, 1:25]\n",
    "        labels = np.apply_along_axis(lambda x: np.argmax(x), 1, labels)\n",
    "        targets.extend(labels)\n",
    "\n",
    "        for idx, file in enumerate(fileNames):\n",
    "            try:\n",
    "                image = Image.open(os.path.join(DATAPATH, data, '{}.tiff'.format(int(file))))\n",
    "                image = np.array(image).astype(np.uint8)\n",
    "            except (TypeError, FileNotFoundError) as te:\n",
    "                image = Image.open(os.path.join(DATAPATH, data, '{}.tiff'.format(idx + 1)))\n",
    "                try:\n",
    "                    image = np.array(image).astype(np.uint8)\n",
    "                except:\n",
    "                    continue\n",
    "            image = compress_image(image, 5)\n",
    "            input_data.append(np.array(image).flatten(order='C'))\n",
    "    input_data = np.vstack(input_data).reshape(-1, 1, height, width)\n",
    "    input_data = input_data.transpose((0, 1, 2, 3))  # convert to HWC CHW\n",
    "    input_data = input_data.reshape(input_data.shape[0], -1)\n",
    "    print(input_data.shape)\n",
    "    print(f'Data Loading Finished. len : {len(input_data)}')\n",
    "    return pd.DataFrame(targets), input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = cem_dataset(train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train - 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "good_idx = X_train >= 0\n",
    "X_train = X_train[good_idx].dropna()\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "good_idx = good_idx.to_numpy().reshape(-1)\n",
    "y_train = y_train[good_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test, y_test = cem_dataset(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = MultiOutputClassifier(RandomForestClassifier(n_estimators=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_df=pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_image = y_pred.reshape(y_pred.shape[0], 1, 20, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "def denorm(img_tensors):\n",
    "    return img_tensors * 1.\n",
    "\n",
    "def show_images(images, nmax=64):\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    s = make_grid(images.detach()[:nmax], nrow=8)\n",
    "    ax.imshow(make_grid(denorm(images.detach()[:nmax]), nrow=8, padding=5, pad_value=0.5).permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "show_images(torch.from_numpy(y_pred_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_prediction_model():\n",
    "    MODEL_JSON_PATH = 'models/cnn_small_rmse_128_300/rmse_rect_1.json'\n",
    "    MODEL_H5_PATH = 'models/cnn_small_rmse_128_300/rmse_rect_1.h5'\n",
    "\n",
    "    # load json and create model\n",
    "    json_file = open(MODEL_JSON_PATH, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(MODEL_H5_PATH)\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prediction_model = get_prediction_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_classes = 12\n",
    "img_height = 20\n",
    "img_width = 40\n",
    "match_cnt = 0\n",
    "correct_cnt_top3 = 0\n",
    "correct_cnt_top5 = 0\n",
    "result_match = dict()\n",
    "result_top3 = dict()\n",
    "result_top5 = dict()\n",
    "result_truth = dict()\n",
    "# Initialize result dict\n",
    "for n in range(n_classes):\n",
    "    wavelength = n * 50 + 1000\n",
    "    result_match[str(wavelength)] = 0\n",
    "    result_top3[str(wavelength)] = 0\n",
    "    result_top5[str(wavelength)] = 0\n",
    "    result_truth[str(wavelength)] = 0\n",
    "print('# of samples', y_pred.shape[0])\n",
    "\n",
    "labels = []\n",
    "predictions = []\n",
    "\n",
    "for i in range(y_pred.shape[0]):\n",
    "    class_int = (i % n_classes)\n",
    "    \n",
    "    predictions.append(class_int)\n",
    "    \n",
    "    wavelength = class_int * 50 + 1000\n",
    "#     single_image = y_pred_image[i] // 255\n",
    "    single_image_for_model = y_pred[i].reshape((1, img_height, img_width, 1))\n",
    "    real = prediction_model.predict(single_image_for_model)\n",
    "\n",
    "    argsort_top5 = (-real).argsort()[:, :5][0] - 12\n",
    "    argsort_top3 = (-real).argsort()[:, :3][0] - 12\n",
    "    \n",
    "    argsort_top5[argsort_top5 < 0] = 0\n",
    "    argsort_top3[argsort_top3 < 0] = 0\n",
    "    label = argsort_top3[0]\n",
    "    labels.append(label)\n",
    "    if class_int in argsort_top5:\n",
    "        result_top5[str(wavelength)] += 1\n",
    "\n",
    "    if class_int in argsort_top3:\n",
    "        result_top3[str(wavelength)] += 1\n",
    "\n",
    "    if class_int == argsort_top3[0]:\n",
    "        result_match[str(wavelength)] += 1\n",
    "\n",
    "    if argsort_top3[0] > -1:\n",
    "        result_truth[str(argsort_top3[0]* 50 + 1000)] += 1\n",
    "        \n",
    "\n",
    "print(f'match_cnt : {sum(result_match.values())}, \\\\t correct_cnt_top3 : {sum(result_top3.values())}, \\\\t correct_cnt_top5 : {sum(result_top5.values())}')\n",
    "\n",
    "percent_match = sum(result_match.values())\n",
    "percent_top3 = sum(result_top3.values())\n",
    "percent_top5 = sum(result_top5.values())\n",
    "\n",
    "print('percent_match : {0:.4f} \\\\t top3 : {1:.4f} \\\\t top5 : {2:.4f}'.format(percent_match, percent_top3, percent_top5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result = np.asarray(result)\n",
    "result[result<0] = -1\n",
    "predictions = result\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels = X_test.reshape(-1)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(labels, predictions)\n",
    "print(predictions)\n",
    "print(labels)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(cm)\n",
    "# Print the precision and recall, among other metrics\n",
    "print(classification_report(labels, predictions, digits=3))\n",
    "recall = recall_score(labels, predictions, average='micro')\n",
    "precision = precision_score(labels, predictions, average='micro')\n",
    "fscore = 2 * recall * precision / (recall + precision)\n",
    "\n",
    "print(f'recall : {recall:.3f}, precision: {precision:.3f}, f-score: {fscore:.3f}')\n",
    "  \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}