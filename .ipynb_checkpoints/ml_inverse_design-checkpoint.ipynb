{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## MaxwellFDFD Data download\n",
    "1. download data from link\n",
    "2. make directory\n",
    "3. unzip dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:03 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:04 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:05 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:06 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:07 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:08 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:09 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:10 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:11 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:12 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:13 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:14 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:15 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:16 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:17 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:18 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:19 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:20 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:21 --:--:--     0\n",
      "100   377    0   377    0     0     17      0 --:--:--  0:00:21 --:--:--    87\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:22 --:--:--     0\n",
      "100 8143k    0 8143k    0     0   354k      0 --:--:--  0:00:23 --:--:-- 8404k\n",
      "100 17.8M    0 17.8M    0     0   760k      0 --:--:--  0:00:24 --:--:-- 9271k\n",
      "100 20.6M    0 20.6M    0     0   882k      0 --:--:--  0:00:24 --:--:-- 9483k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o maxwellfdfd.zip https://drive.google.com/uc?id=14-Bl89OzRtLM1MCW2H81Xvivq8EvTrmB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#!mkdir maxwellfdfd\n",
    "#!unzip maxwellfdfd.zip -d ./maxwellfdfd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML(Random Forest regressor):\n",
    "1. create model for Multi-output Random Forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\2.CEM\\\\maxwellfdfd-controlgan\\\\maxwellfdfd'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "data_dir = os.path.join(os.getcwd(), 'maxwellfdfd')\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compress_image(prev_image, n):\n",
    "    if n < 2:\n",
    "        return prev_image\n",
    "\n",
    "    height = prev_image.shape[0] // n\n",
    "    width = prev_image.shape[1] // n\n",
    "    new_image = np.zeros((height, width), dtype=int)\n",
    "    for i in range(0, height):\n",
    "        for j in range(0, width):\n",
    "            new_image[i, j] = prev_image[n * i, n * j]\n",
    "\n",
    "    return new_image\n",
    "\n",
    "DATASETS_TRAIN = [\n",
    "    'binary_501',\n",
    "    'binary_502',\n",
    "    'binary_503',\n",
    "    'binary_504',\n",
    "    'binary_505',\n",
    "    'binary_506',\n",
    "    'binary_507',\n",
    "    'binary_508',\n",
    "    'binary_509',\n",
    "    'binary_510',\n",
    "    'binary_511',\n",
    "    'binary_512',\n",
    "    'binary_1001',\n",
    "    'binary_1002',\n",
    "    'binary_1003',\n",
    "    'binary_rl_fix_501',\n",
    "    'binary_rl_fix_502',\n",
    "    'binary_rl_fix_503',\n",
    "    'binary_rl_fix_504',\n",
    "    'binary_rl_fix_505',\n",
    "    'binary_rl_fix_506',\n",
    "    'binary_rl_fix_507',\n",
    "    'binary_rl_fix_508',\n",
    "    'binary_rl_fix_509',\n",
    "    'binary_rl_fix_510',\n",
    "    'binary_rl_fix_511',\n",
    "    'binary_rl_fix_512',\n",
    "    'binary_rl_fix_513',\n",
    "    'binary_rl_fix_514',\n",
    "    'binary_rl_fix_515',\n",
    "    'binary_rl_fix_516',\n",
    "    'binary_rl_fix_517',\n",
    "    'binary_rl_fix_518',\n",
    "    'binary_rl_fix_519',\n",
    "    'binary_rl_fix_520',\n",
    "    'binary_rl_fix_1001',\n",
    "    'binary_rl_fix_1002',\n",
    "    'binary_rl_fix_1003',\n",
    "    'binary_rl_fix_1004',\n",
    "    'binary_rl_fix_1005',\n",
    "    'binary_rl_fix_1006',\n",
    "    'binary_rl_fix_1007',\n",
    "    'binary_rl_fix_1008',\n",
    "]\n",
    "\n",
    "DATASETS_TEST = [\n",
    "    'binary_new_test_501',\n",
    "    'binary_new_test_1501',\n",
    "    'binary_test_1101',\n",
    "]\n",
    "\n",
    "def cem_dataset(train=True):\n",
    "    if train:\n",
    "        DATAPATH = os.path.join(data_dir, 'train')\n",
    "        DATASETS = DATASETS_TRAIN\n",
    "    else:\n",
    "        DATAPATH = os.path.join(data_dir, 'test')\n",
    "        DATASETS = DATASETS_TEST\n",
    "    width = 40\n",
    "    height = 20\n",
    "    input_data = []\n",
    "    targets = []\n",
    "    # load Train dataset\n",
    "    for data in DATASETS:\n",
    "        dataframe = pd.read_csv(os.path.join(DATAPATH, '{}.csv'.format(data)), delim_whitespace=False, header=None)\n",
    "        dataset = dataframe.values\n",
    "\n",
    "        # split into input (X) and output (Y) variables\n",
    "        fileNames = dataset[:, 0]\n",
    "\n",
    "        # 1. first try max\n",
    "        dataset[:, 1:25] /= 2767.1\n",
    "\n",
    "        # 2. Classification or Regression,\n",
    "        labels = dataset[:, 1:25]\n",
    "        labels = np.apply_along_axis(lambda x: np.argmax(x), 1, labels)\n",
    "        targets.extend(labels)\n",
    "\n",
    "        for idx, file in enumerate(fileNames):\n",
    "            try:\n",
    "                image = Image.open(os.path.join(DATAPATH, data, '{}.tiff'.format(int(file))))\n",
    "                image = np.array(image).astype(np.uint8)\n",
    "            except (TypeError, FileNotFoundError) as te:\n",
    "                image = Image.open(os.path.join(DATAPATH, data, '{}.tiff'.format(idx + 1)))\n",
    "                try:\n",
    "                    image = np.array(image).astype(np.uint8)\n",
    "                except:\n",
    "                    continue\n",
    "            image = compress_image(image, 5)\n",
    "            input_data.append(np.array(image).flatten(order='C'))\n",
    "    input_data = np.vstack(input_data).reshape(-1, 1, height, width)\n",
    "    input_data = input_data.transpose((0, 1, 2, 3))  # convert to HWC CHW\n",
    "    input_data = input_data.reshape(input_data.shape[0], -1)\n",
    "    print(input_data.shape)\n",
    "    print(f'Data Loading Finished. len : {len(input_data)}')\n",
    "    return pd.DataFrame(targets), input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27000, 800)\n",
      "Data Loading Finished. len : 27000\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = cem_dataset(train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train - 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26993</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26994</th>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26996</th>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26997</th>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26999</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24350 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0       6.0\n",
       "1       7.0\n",
       "2       5.0\n",
       "3       3.0\n",
       "4       5.0\n",
       "...     ...\n",
       "26993   6.0\n",
       "26994  11.0\n",
       "26996  11.0\n",
       "26997  11.0\n",
       "26999   9.0\n",
       "\n",
       "[24350 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_idx = X_train >= 0\n",
    "X_train = X_train[good_idx].dropna()\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "good_idx = good_idx.to_numpy().reshape(-1)\n",
    "y_train = y_train[good_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 800)\n",
      "Data Loading Finished. len : 3000\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = cem_dataset(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    model = MultiOutputClassifier(RandomForestClassifier(n_estimators=100))\n",
    "    model.fit(X_train, y_train)\n",
    "    models.append(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_df=pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_image = y_pred.reshape(y_pred.shape[0], 1, 20, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "def denorm(img_tensors):\n",
    "    return img_tensors * 1.\n",
    "\n",
    "def show_images(images, nmax=64):\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    s = make_grid(images.detach()[:nmax], nrow=8)\n",
    "    ax.imshow(make_grid(denorm(images.detach()[:nmax]), nrow=8, padding=5, pad_value=0.5).permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdAAAABVCAYAAAD5V7XfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8+yak3AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOOElEQVR4nO3df1AUdR8H8PfeLfcLlePAgU5TIASHUQeUkszCsYnSMZwUKExLA7GwYVKcMjUrm2T6MUPp1Aw4U5Oj5TiGyUx/0JApWjYqjpZOWpQ+po5lKFx4x3E/9vnD5zau3RNuPTx5fL/+4/vd/e7ne8vu+3ZvDwRJkkBERETh0UW7ACIiosGIAUpERKQBA5SIiEgDBigREZEGDFAiIiINGKBEREQaiOEsbLFYJKvVOkClEBER3Vo6OjrgdDoFtb6wAtRqtaKioiIyVREREd3i6uvrQ/bxFi4REZEGDFAiIiINGKBEREQahPUZaCibNm2Cy+WKxFBRU1FRAZPJpGjfunUr2tvbo1BR5MyfPx82m03R3tjYiDNnztz8giJo9uzZGD16tKJ97969OHbsWBQqipxp06ZhwoQJivZjx45h7969UagocnJycnD//fcr2s+cOYPGxsYoVBQ5aWlpmDVrlqK9vb0dW7dujUJFkZOYmIh58+Yp2l0uFzZt2hSFiiLHYrGgvLw8rHUiEqD/e0opEkNFTag/qu9wOHDlypWbXE1k+Xw+1faurq5BPzePx6Pa7nK5Bv3c3G53yPbBPrdQ5wuPxzPo59bV1aXa7vP5Bv3cDAaDarskSYN+bj09PWGvw1u4REREGjBAiYiINGCAEhERacAAJSIi0oABSkREpAEDlIiISAMGKBERkQYMUCIiIg0YoERERBowQImIiDRggBIREWnAACUiItKAAUpERKQBA5SIiEgDBigR0SA2YsQIHDp0CIcOHcL48eOjXc5tJSL/D5SIiAae0WjEmjVrIAgCtm3bhuPHj8NoNCI3NxcAsHz5cpw/f/66Y0iShDfeeEPT/7+kYAxQIqJb1L333gud7p8bhbGxsVi9ejUEQYDb7UZcXBzsdrvcv3Dhwj7HlCQJLS0tcDqd+P3333H27NmBKP22cFsHqF6vh8FggMvlinYpEScIAsxmMwAEHYBE/68MBgNEUYTf70d3d3dQn06ng8lkAgC4XC5IkqRY32g0wu/3w+PxAAAsFgsAwO12w+fzDXD1/xBFEQaDAXq9Hrt375br/rd169Zh3bp1YY8vCAK++uorAMCbb76JNWvW3FC9t7Pb+sw6c+ZM/Prrr9EuY0BMmDABDocDDocDY8eOjXY5RANuy5YtcDgcOHr0qKLvvvvuk4+HkSNHqq7f1NQkh4nFYkFHRwccDgfmz58/kGUrlJWVweFw4MqVKzAajTd12xSeiFyBHjhwAEajEZ9++qmmd0TRIggChg8fjpMnT6KhoQFut1uxTGNjI6xWK/bt24fFixdHoUrt9Hr9dfvr6upgt9vR1taGWbNm3aSqiCJn2LBhOHjwIADAbrdDr9cjNTUVJ0+eBAAUFxfjxx9/BPDP8bBnzx75KrO3O++8Ey0tLfLPer0eOp0OgiBEpNYxY8bIdRUWFuLnn38O6v/222+RkJAAq9Xa57E72HzxxRcYO3Ys9u/fj/LycgDA/v37kZiYiO3bt2Pt2rU3NH5OTg4+++yzkP25ubno6uq6oW2oiUiA3nXXXYiNjUVxcTGSkpLk9pqaGpw7d06xfFlZGSZOnBjU9s477+DMmTNhbzsmJga1tbUQBAFbtmzBgQMHEBcXh/Xr1wMANmzYgFOnTgWt88orryA5ORkpKSkQRREZGRkhb3OmpKQgKSkJp0+fDprXsGHDsH//fsVOmz17NgoKCuByubBixYqw5wNc29mLFi2CJEmorq5WDfbehg0bhpqaGgDAxo0b5YO0LyNGjEBGRgaGDx+ODz74AACwfv36Ph9CiLSJEyeirKwMAFBdXa24/RZQWlqKqVOnBrV1dHSoPgxRVFSEp556Kqitrq4OP/zwQ4Sqjox3330XZrMZzc3N2LlzZ7/Wyc/PV7zh+fzzz7F79+6BKPGWodPpUFtbC1EU0dDQgK+//ho6nQ4ZGRlBIWcwGJCZmQkAWLt2Lf7880/ccccdcn9aWlrIbcyYMQMJCQkQRVEec8GCBbj77rvR0dGB1atXAwCqqqqQmZmJs2fP4q233upX/UajUa4rcGWZlZWFpUuXAgCys7Pl28Y3yyOPPIL4+Pigtq1bt+K7774La5whQ4bI55APP/wQJ06cCOpPSUlBZmYmzGazvFx2djZiY2Mxd+5cJCQk9LmNjz/+GIcPHw5qq66uRlpaGpKTk+XX9t8kSUJtbW3QecLj8WDZsmWqt/LDEdHPQMeNG4dx48bB7/ejqakJBoNBdbmHH34YxcXFQW2bN2/WFKCiKOLZZ5+FXq9Ha2srDhw4gNjYWFRWVgIAGhoaFAFqt9sxY8YMjB49OuztAdc+qE9OToZer1cEaF5eHiorK9HZ2RkUoCNHjkR6ejr27NnT5/jp6emorKyEJEl4+eWX+wxQi8Uiz3fnzp39DtAAm80mr19fX3/TA7T3fFetWhUyQPPz87FkyZKgti1btqCtrU2x7NSpU5GXlxfU1tTUdMsFaFlZGaxWK65evdrvAB0/fjxmzpwZ1NbW1vZ/H6CCIGDJkiU4ePAgmpub+7VOUVFRWNvIzc2Vn2gNmD59OqZPn47z58/LAVpYWIgHH3wQra2t/Q5QNaNGjZKPvWiYNGkSJk2aFNR25MiRsAPUZDLhueeegyAI+PLLLxUBGqA236ysLGRlZfW5jX379ikCdM6cOZgyZcp11xMEQb7qDeju7kZ1dfUNf7YdkQB1uVxB7wB9Ph9KS0vR09MjP8jSm8/ng9PpDGqLiYlRXbYvZrMZLpcLOp0OOp0OZrMZRqNRHl8URcW4y5cvh9frxTPPPNPn+N3d3XA6nfB6vfI4brcbTqcTfr9fMbYkSXA6neju7g7qKygowIoVKxS/rGr0er1cv8lkgtfrve7yavM1GAxym9/vV10vMI/eDAaDpv1wI3Q6XdB8Qz1e7/f7FfWGOgA8Ho9iWbXfhWgL/H5JkqSoTRTVD0+146f3Q2ODQUxMjGp74BhWo9fr4XK5UF1djePHj8NsNsNkMt20hwB7H9NerxdOpxMej0dRb6gLh8C5IbCM2WyGKIqKfRlt19sHoR5oAiDvB7XjrKen54bnqdfrFeOqHef94Xa7YTKZgs6N15tbKEI4l7B2u12qqKgIeyNERESDUX19PS5cuKD6Qfht/RQuERGRVgxQIiIiDRigREREGjBAiYiINGCAEhERaRCRr7Fs3LjxlnsUO1xVVVWqj25/9NFHuHTpUhQqipyysjIkJiYq2nfs2DHo/5RhSUkJUlNTFe3Nzc1obW2NQkWRU1BQgJycnGiXQUQhRCRAu7u7Q375fbBzu92Dfm6hvqrU09Mz6OcW6nugXq930M+tr+//ElF08RYuERGRBgxQIiIiDRigREREGjBAiYiINGCAEhERacAAJSIi0oABSkREpAEDlIiISAMGKBERkQYMUCIiIg0YoERERBowQImIiDRggBIREWnAACUiItKAAUpERKQBA5SIiEgDBigREZEGDFAiIiINGKBEREQaMEAp4urq6nDp0iW0trZGuxQiogEjDvQGFi5ciMcee0y17+LFi1iyZElQW1ZWFmpqagAAZWVl+Ouvv1TXLSkpwZNPPgm3243HH38ckiQBAKZMmYLFixdj0aJFAIB169bht99+Q0tLC2prawEAS5cuxblz5/pV/4YNG2A2m3HkyBG8/vrrAIBPPvkEVqtVXsbv96OkpAQej+e6YyUlJaG+vh4A8OKLL+LUqVOqyz3wwAOorq4GADzxxBNwuVwoKirCggUL0NPTg5KSEkiShKVLl6KgoEB1jNOnT+OFF17o1xx7e++995CamoqjR4/i1VdfDep76KGH8Pzzz0OSJBQXF6Ompgbff/89duzYAbPZjG3btgEAJk2ahMTERFgsFuzatQsAsHLlSvz000/IzMzE22+/DQCoqKjAH3/8oVrHnDlz8PTTT6v2dXR0hOy7nlWrVmHy5MlhrzeQ5s2bh6tXr0a7DCLSYMADNCsrC4WFhap9bW1tijabzSYvX15ejsuXL+OXX37BN998E7RcRkYGJk+ejO3bt8tt+fn5yMvLCzopX758GQ6HA3FxcfK4L730Ur/rnzZtGpKSkmAwGOS2goICJCcnyz97vV7odH1fzMfGxso1BN4k9FZaWorDhw/DbrejsLAQkiRBFK/tojFjxqCwsBAulwuCIECSJEyYMCHka3v06NF+z7G3/Px8ZGdnw2w2K/pGjRqFwsJC+P1+VFRUYO7cuWhvbwcAiKKIRx99FIIgyMtbLBa5vkBoxsfHy23Lli0LWUd6enrIuV28eFHT3O65556QY0ZD7/1LRINPRI7e+Ph4mEwm1T6/3y+fZP/t77//hs1mC2qzWCzy8itWrAAA7Nq1C8eOHVOsf+LECbz22muIj48HcC2AhgwZgqqqKnnczZs3A7gW5IFxhw4dqthu7xN/b52dnRBFEd3d3fI6nZ2diImJCZpjfHw8enp6VMcIGDp0qFyDxWJR1LBy5Uq8//778Hq98nJWqxUxMTEQBAHt7e1wu92w2Wzw+/3w+XwhX9uuri55fL1eH7Kef9fQ1dWF9vZ2uFwuRZ8oivL2AlfjgiDAZrMhNjYWly9fDjl3s9kMm80WtH/Vth8QmK+azs5Oeb3e+6E3tdfX7XaHHDNarFZryP0T6pgioluDELj12R92u12qqKgYwHKIiIhuHfX19bhw4YLqFRYfIiIiItKAAUpERKQBA5SIiEgDBigREZEGDFAiIiINwnoKVxCESwD+M3DlEBER3VJGS5I0XK0jrAAlIiKia3gLl4iISAMGKBERkQYMUCIiIg0YoERERBowQImIiDRggBIREWnAACUiItKAAUpERKQBA5SIiEiD/wKRvK1c8XmJpAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_images(torch.from_numpy(y_pred_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "def get_prediction_model():\n",
    "    MODEL_JSON_PATH = 'models/cnn_small_rmse_128_300/rmse_rect_1.json'\n",
    "    MODEL_H5_PATH = 'models/cnn_small_rmse_128_300/rmse_rect_1.h5'\n",
    "\n",
    "    # load json and create model\n",
    "    json_file = open(MODEL_JSON_PATH, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(MODEL_H5_PATH)\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prediction_model = get_prediction_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of samples 12\n",
      "match_cnt : 3, \\t correct_cnt_top3 : 4, \\t correct_cnt_top5 : 6\n",
      "percent_match : 0.2500 \\t top3 : 0.3333 \\t top5 : 0.5000\n"
     ]
    }
   ],
   "source": [
    "n_classes = 12\n",
    "img_height = 20\n",
    "img_width = 40\n",
    "match_cnt = 0\n",
    "correct_cnt_top3 = 0\n",
    "correct_cnt_top5 = 0\n",
    "result_match = dict()\n",
    "result_top3 = dict()\n",
    "result_top5 = dict()\n",
    "result_truth = dict()\n",
    "# Initialize result dict\n",
    "for n in range(n_classes):\n",
    "    wavelength = n * 50 + 1000\n",
    "    result_match[str(wavelength)] = 0\n",
    "    result_top3[str(wavelength)] = 0\n",
    "    result_top5[str(wavelength)] = 0\n",
    "    result_truth[str(wavelength)] = 0\n",
    "print('# of samples', y_pred.shape[0])\n",
    "\n",
    "labels = []\n",
    "predictions = []\n",
    "\n",
    "for i in range(y_pred.shape[0]):\n",
    "    class_int = (i % n_classes)\n",
    "    \n",
    "    predictions.append(class_int)\n",
    "    \n",
    "    wavelength = class_int * 50 + 1000\n",
    "#     single_image = y_pred_image[i] // 255\n",
    "    single_image_for_model = y_pred[i].reshape((1, img_height, img_width, 1))\n",
    "    real = prediction_model.predict(single_image_for_model)\n",
    "\n",
    "    argsort_top5 = (-real).argsort()[:, :5][0] - 12\n",
    "    argsort_top3 = (-real).argsort()[:, :3][0] - 12\n",
    "    \n",
    "    argsort_top5[argsort_top5 < 0] = 0\n",
    "    argsort_top3[argsort_top3 < 0] = 0\n",
    "    label = argsort_top3[0]\n",
    "    labels.append(label)\n",
    "    if class_int in argsort_top5:\n",
    "        result_top5[str(wavelength)] += 1\n",
    "\n",
    "    if class_int in argsort_top3:\n",
    "        result_top3[str(wavelength)] += 1\n",
    "\n",
    "    if class_int == argsort_top3[0]:\n",
    "        result_match[str(wavelength)] += 1\n",
    "\n",
    "    if argsort_top3[0] > -1:\n",
    "        result_truth[str(argsort_top3[0]* 50 + 1000)] += 1\n",
    "        \n",
    "\n",
    "print(f'match_cnt : {sum(result_match.values())}, \\\\t correct_cnt_top3 : {sum(result_top3.values())}, \\\\t correct_cnt_top5 : {sum(result_top5.values())}')\n",
    "\n",
    "percent_match = sum(result_match.values()) / (n_classes)\n",
    "percent_top3 = sum(result_top3.values())  / (n_classes)\n",
    "percent_top5 = sum(result_top5.values())  / (n_classes)\n",
    "\n",
    "print('percent_match : {0:.4f} \\\\t top3 : {1:.4f} \\\\t top5 : {2:.4f}'.format(percent_match, percent_top3, percent_top5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11] [6, 0, 9, 7, 0, 0, 11, 8, 9, 6, 10, 11]\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "print(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "print(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "[6, 0, 9, 7, 0, 0, 11, 7, 10, 7, 10, 11]\n",
      "[[0 1 0 0 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 1 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 1 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000         3\n",
      "           1      0.000     0.000     0.000         0\n",
      "           2      0.000     0.000     0.000         0\n",
      "           3      0.000     0.000     0.000         0\n",
      "           4      0.000     0.000     0.000         0\n",
      "           5      0.000     0.000     0.000         0\n",
      "           6      0.000     0.000     0.000         1\n",
      "           7      1.000     0.333     0.500         3\n",
      "           8      0.000     0.000     0.000         0\n",
      "           9      0.000     0.000     0.000         1\n",
      "          10      1.000     0.500     0.667         2\n",
      "          11      1.000     0.500     0.667         2\n",
      "\n",
      "    accuracy                          0.250        12\n",
      "   macro avg      0.250     0.111     0.153        12\n",
      "weighted avg      0.583     0.250     0.347        12\n",
      "\n",
      "recall : 0.250, precision: 0.250, f-score: 0.250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\maxwellfdfd-controlgan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda3\\envs\\maxwellfdfd-controlgan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda3\\envs\\maxwellfdfd-controlgan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(labels, predictions)\n",
    "print(predictions)\n",
    "print(labels)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(cm)\n",
    "# Print the precision and recall, among other metrics\n",
    "print(classification_report(labels, predictions, digits=3))\n",
    "recall = recall_score(labels, predictions, average='micro')\n",
    "precision = precision_score(labels, predictions, average='micro')\n",
    "fscore = 2 * recall * precision / (recall + precision)\n",
    "\n",
    "print(f'recall : {recall:.3f}, precision: {precision:.3f}, f-score: {fscore:.3f}')\n",
    "  \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
